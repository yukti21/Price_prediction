# -*- coding: utf-8 -*-
"""ibm-major-project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/146zumDbiIQQfwahaKhIvmQM9E0P3i-cb

## Import Libraries
"""

from matplotlib import pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from collections import Counter
import xgboost


"""Defining function for regression metrics"""

def Reg_Models_Evaluation_Metrics (model,X_train,y_train,X_test,y_test,y_pred):
    cv_score = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10)
    r2 = model.score(X_test, y_test)
    n = X_test.shape[0]
    p = X_test.shape[1]
    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)
    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))
    R2 = model.score(X_test, y_test)
    CV_R2 = cv_score.mean()
    return R2, adjusted_r2, CV_R2, RMSE
    print('RMSE:', round(RMSE,4))
    print('R2:', round(R2,4))
    print('Adjusted R2:', round(adjusted_r2, 4) )
    print("Cross Validated R2: ", round(cv_score.mean(),4) )

"""## Import Data"""

try:
    raw_df1 = pd.read_csv('../input/avocado-prices/avocado.csv')
except:
    raw_df1 = pd.read_csv('avocado.csv')

raw_df1

raw_df1.columns

# Deleting column
raw_df1 = raw_df1.drop('Unnamed: 0', axis = 1)

numeric_columns = ['AveragePrice', 'Total Volume','4046', '4225', '4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags']
categorical_columns = ['Region', 'Type']
time_columns = ['Data', 'Year']

raw_df1.head()

"""# Some visualisations

## Avocado Prices
"""

# Checking for distributions
def dist_custom(dataset, columns_list, rows, cols, suptitle):
    fig, axs = plt.subplots(rows, cols,figsize=(16,16))
    fig.suptitle(suptitle,y=1, size=25)
    axs = axs.flatten()
    for i, data in enumerate(columns_list):
        sns.kdeplot(dataset[data], ax=axs[i], fill=True,  alpha=.5, linewidth=0)
        axs[i].set_title(data + ', skewness is '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))

dist_custom(dataset=raw_df1, columns_list=numeric_columns, rows=3, cols=3, suptitle='Skewness of each column')
plt.tight_layout()

"""# Data pre-processing

##Some transformations
"""

# Changing data types
for i in raw_df1.columns:
    if i == 'Date':
        raw_df1[i] = raw_df1[i].astype('datetime64[ns]')
    elif raw_df1[i].dtype == 'object':
        raw_df1[i] = raw_df1[i].astype('category')

df1 = raw_df1.copy()

df1['Date'] = pd.to_datetime(df1['Date'])
df1['month'] = df1['Date'].dt.month

df1['Spring'] = df1['month'].between(3,5,inclusive='both')
df1['Summer'] = df1['month'].between(6,8,inclusive='both')
df1['Fall'] = df1['month'].between(9,11,inclusive='both')
df1['Winter'] = df1['month'].between(12,2,inclusive='both')

df1.Spring = df1.Spring.replace({True: 1, False: 0})
df1.Summer = df1.Summer.replace({True: 1, False: 0})
df1.Fall = df1.Fall.replace({True: 1, False: 0})
df1.Winter = df1.Winter.replace({True: 1, False: 0})

# Encoding labels for 'type'
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df1['type'] = le.fit_transform(df1['type'])

# Encoding 'region' (One Hot Encoding)
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(drop='first', handle_unknown='ignore')
ohe = pd.get_dummies(data=df1, columns=['region'])

df1 = ohe.drop(['Date','Small Bags','Large Bags','XLarge Bags'], axis=1)

"""## Outlier detection and removal"""

def IQR_method (df,n,features):
    outlier_list = []
    
    for column in features:
                
        # 1st quartile (25%)
        Q1 = np.percentile(df[column], 25)
        # 3rd quartile (75%)
        Q3 = np.percentile(df[column],75)
        
        # Interquartile range (IQR)
        IQR = Q3 - Q1
        
        # outlier step
        outlier_step = 1.5 * IQR
        
        # Determining a list of indices of outliers
        outlier_list_column = df[(df[column] < Q1 - outlier_step) | (df[column] > Q3 + outlier_step )].index
        
        # appending the list of outliers 
        outlier_list.extend(outlier_list_column)
        
    # selecting observations containing more than x outliers
    outlier_list = Counter(outlier_list)        
    multiple_outliers = list( k for k, v in outlier_list.items() if v > n )
    
    # Calculate the number of records below and above lower and above bound value respectively
    df1 = df[df[column] < Q1 - outlier_step]
    df2 = df[df[column] > Q3 + outlier_step]
    
    print('Total number of deleted outliers:', df1.shape[0]+df2.shape[0])
    
    return multiple_outliers

numeric_columns2 = ['Total Volume', 'Total Bags']

Outliers_IQR = IQR_method(df1,1,numeric_columns2)
# dropping outliers
df1 = df1.drop(Outliers_IQR, axis = 0).reset_index(drop=True)

df1.columns

"""##  Train test split"""

X = df1.drop('AveragePrice', axis=1)
y = df1['AveragePrice']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

"""##  Feature scaling"""

from sklearn.preprocessing import StandardScaler

# Creating function for scaling
def Standard_Scaler (df, col_names):
    features = df[col_names]
    scaler = StandardScaler().fit(features.values)
    features = scaler.transform(features.values)
    df[col_names] = features
    return df

col_names = ['Total Volume','4046','4225','4770', 'Total Bags',]
X_train = Standard_Scaler (X_train, col_names)
X_test = Standard_Scaler (X_test, col_names)

X_train

X_train['Winter']=X_train['Winter'].astype('int')
X_test['Winter']=X_test['Winter'].astype('int')

"""#Comparing different models

## Linear Regression
"""

from sklearn.linear_model import LinearRegression

lm = LinearRegression()
lm.fit(X_train, y_train)
y_pred = lm.predict(X_test)

ndf = [Reg_Models_Evaluation_Metrics(lm,X_train,y_train,X_test,y_test,y_pred)]

lm_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])
lm_score.insert(0, 'Model', 'Linear Regression')
lm_score

plt.figure(figsize = (10,5))
sns.regplot(x=y_test,y=y_pred)
plt.title('Linear regression for Avocado dataset', fontsize = 20)

"""## Random Forest"""

from sklearn.ensemble import RandomForestRegressor

# Creating and training model
RandomForest_reg = RandomForestRegressor(n_estimators = 10, random_state = 0)

"""### Random Forest performance for Avocado dataset"""

RandomForest_reg.fit(X_train, y_train)
y_pred = RandomForest_reg.predict(X_test)

ndf = [Reg_Models_Evaluation_Metrics(RandomForest_reg,X_train,y_train,X_test,y_test,y_pred)]

rf_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])
rf_score.insert(0, 'Model', 'Random Forest')
rf_score

"""##  Ridge Regression"""

from sklearn.linear_model import Ridge

# Creating and training model
ridge_reg = Ridge(alpha=3, solver="cholesky")

"""### Ridge Regression performance for Avocado dataset"""

ridge_reg.fit(X_train, y_train)
# Model making a prediction on test data
y_pred = ridge_reg.predict(X_test)

ndf = [Reg_Models_Evaluation_Metrics(ridge_reg,X_train,y_train,X_test,y_test,y_pred)]

rr_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])
rr_score.insert(0, 'Model', 'Ridge Regression')
rr_score

"""## XGBoost"""

from xgboost import XGBRegressor
# create an xgboost regression model
XGBR = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.8, colsample_bytree=0.8)

X_train

"""### XGBoost performance for Avocado dataset"""

XGBR.fit(X_train, y_train)
# Model making a prediction on test data
y_pred = XGBR.predict(X_test)

ndf = [Reg_Models_Evaluation_Metrics(XGBR,X_train,y_train,X_test,y_test,y_pred)]

XGBR_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])
XGBR_score.insert(0, 'Model', 'XGBoost')
XGBR_score

"""##  Recursive Feature Elimination (RFE)

RFE is a wrapper-type feature selection algorithm. This means that a different machine learning algorithm is given and used in the core of the method, is wrapped by RFE, and used to help select features.
"""

from sklearn.feature_selection import RFE
from sklearn.pipeline import Pipeline

# create pipeline
rfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=60)
model = RandomForestRegressor()
rf_pipeline = Pipeline(steps=[('s',rfe),('m',model)])

"""### Random Forest RFE performance for Avocado dataset"""

rf_pipeline.fit(X_train, y_train)
y_pred = rf_pipeline.predict(X_test)

ndf = [Reg_Models_Evaluation_Metrics(rf_pipeline,X_train,y_train,X_test,y_test,y_pred)]

rfe_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])
rfe_score.insert(0, 'Model', 'Random Forest with RFE')
rfe_score

from sklearn.feature_selection import RFE
from sklearn.pipeline import Pipeline
from xgboost import XGBRegressor
rfe = RFE(estimator=XGBRegressor(n_estimators=1500, max_depth=7, eta=0.1, subsample=0.8, colsample_bytree=0.8), n_features_to_select=60)
model = XGBRegressor(n_estimators=1500, max_depth=7, eta=0.1, subsample=0.8, colsample_bytree=0.8)
xg_pipeline = Pipeline(steps=[('s',rfe),('m',model)])

xg_pipeline.fit(X_train, y_train)
y_pred = xg_pipeline.predict(X_test)

ndf = [Reg_Models_Evaluation_Metrics(xg_pipeline,X_train,y_train,X_test,y_test,y_pred)]

xgrfe_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])
xgrfe_score.insert(0, 'Model', 'Xgboost with RFE')
xgrfe_score



"""#Final Model Evaluation"""

predictions = pd.concat([xgrfe_score,rfe_score, XGBR_score, rr_score, rf_score, lm_score], ignore_index=True, sort=False)
predictions



from sklearn.model_selection import GridSearchCV

alpha_params = [{'n_estimators': [500,1000,1500]},
                {'max_depth': [5,6,7]}]

clf = GridSearchCV(model, alpha_params, cv = 10)

clf.fit(X_train, y_train)
# Model making a prediction on test data
#y_pred = ridge_pipe.predict(X_test)
# The combination of hyperparameters along with values that give the best performance of our estimate specified
print(clf.best_params_)

clf.best_score_

clf.best_estimator_

clf.best_params_

model.save('final_model.h5')

import pickle
pickle.dump(XGBR, open('model_xgboost.pkl', 'wb'))

model1 = pickle.load(open('model_xgboost.pkl', 'rb'))

df1['Spring'] = df1['month'].between(3,5,inclusive='both')
df1['Summer'] = df1['month'].between(6,8,inclusive='both')
df1['Fall'] = df1['month'].between(9,11,inclusive='both')
df1['Winter'] = df1['month'].between(12,2,inclusive='both')

from sklearn.preprocessing import StandardScaler

# Creating function for scaling
def Standard_Scaler (df, col_names):
    features = df[col_names]
    scaler = StandardScaler().fit(features.values)
    features = scaler.transform(features.values)
    df[col_names] = features
    return df
col_names = ['Total Volume','4046','4225','4770', 'Total Bags']

def predict(Total_Volume, small, medium, large, Total_Bags, Type, year, month, region):
  data=[Total_Volume, small, medium, large, Total_Bags, Type, year, month]
  regions=['region_Albany',
       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',
       'region_Boston', 'region_BuffaloRochester', 'region_California',
       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',
       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',
       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',
       'region_HarrisburgScranton', 'region_HartfordSpringfield',
       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',
       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',
       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',
       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',
       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',
       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',
       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',
       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',
       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',
       'region_SouthCentral', 'region_Southeast', 'region_Spokane',
       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',
       'region_West', 'region_WestTexNewMexico']
  print(month)
  if(month==8):
    print(8)
  if(month==3 or 4 or 5):
    data.extend([1,0,0,0])
  elif(month==6 or 7 or 8):
    print('True')
    data.extend([0,1,0,0])
  elif(month==9 or 10 or 11):
    data.extend([0,0,1,0])
  elif(month==12 or 1 or 2):
    data.extend([0,0,0,1])
  index=0
  arr=np.zeros(54)
  for i in range(len(regions)):
    if(regions[i][7:]==region):
      index=i
      break
  arr[index]=1
  l=arr.tolist()
  data.extend(l)
  print(data)
  df=pd.DataFrame(data=[data],columns=['Total Volume', '4046', '4225', '4770', 'Total Bags', 'type', 'year',
        'month', 'Spring', 'Summer', 'Fall', 'Winter', 'region_Albany',
        'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',
        'region_Boston', 'region_BuffaloRochester', 'region_California',
        'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',
        'region_Columbus', 'region_DallasFtWorth', 'region_Denver',
        'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',
        'region_HarrisburgScranton', 'region_HartfordSpringfield',
        'region_Houston', 'region_Indianapolis', 'region_Jacksonville',
        'region_LasVegas', 'region_LosAngeles', 'region_Louisville',
        'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',
        'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',
        'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',
        'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',
        'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',
        'region_Roanoke', 'region_Sacramento', 'region_SanDiego',
        'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',
        'region_SouthCentral', 'region_Southeast', 'region_Spokane',
        'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',
        'region_West', 'region_WestTexNewMexico'])
  df = Standard_Scaler (df, col_names)
  model = pickle.load(open('model_xgboost.pkl', 'rb'))
  prediction=model.predict(df)
  return prediction

from sklearn.preprocessing import StandardScaler

# Creating function for scaling
def Standard_Scaler (df, col_names):
    features = df[col_names]
    scaler = StandardScaler().fit(features.values)
    features = scaler.transform(features.values)
    df[col_names] = features
    return df
col_names = ['Total Volume','4046','4225','4770', 'Total Bags']
Total_Volume=0 
small=0 
medium=0 
large=0 
Total_Bags=0 
Type=1
year=2015
month=5
region="Albany"
data=[Total_Volume, small, medium, large, Total_Bags, Type, year, month]
regions=['region_Albany',
       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',
       'region_Boston', 'region_BuffaloRochester', 'region_California',
       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',
       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',
       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',
       'region_HarrisburgScranton', 'region_HartfordSpringfield',
       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',
       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',
       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',
       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',
       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',
       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',
       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',
       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',
       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',
       'region_SouthCentral', 'region_Southeast', 'region_Spokane',
       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',
       'region_West', 'region_WestTexNewMexico']
print(month)
if(month==8):
  print(8)
if(month==3 or 4 or 5):
  data.extend([1,0,0,0])
elif(month==6 or 7 or 8):
  print('True')
  data.extend([0,1,0,0])
elif(month==9 or 10 or 11):
  data.extend([0,0,1,0])
elif(month==12 or 1 or 2):
  data.extend([0,0,0,1])
index=0
arr=np.zeros(54)
for i in range(len(regions)):
  if(regions[i][7:]==region):
    index=i
    break
arr[index]=1
l=arr.tolist()
  #data={'Total Volume': [Total_Volume], '4046': [small], '4225':[medium], '4770':[large], 'Total Bags':[Total_Bags], 'type': [Type], 'year':[year], 'month':[month]}
  # input_data= pd.DataFrame(data=[Total_Volume, small, medium, large, Total_Bags, Type, year, month], columns=['Total Volume', '4046', '4225', '4770', 'Total Bags', 'type', 'year',
  #      'month', 'Spring', 'Summer', 'Fall', 'Winter', 'region_Albany',
  #      'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',
  #      'region_Boston', 'region_BuffaloRochester', 'region_California',
  #      'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',
  #      'region_Columbus', 'region_DallasFtWorth', 'region_Denver',
  #      'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',
  #      'region_HarrisburgScranton', 'region_HartfordSpringfield',
  #      'region_Houston', 'region_Indianapolis', 'region_Jacksonville',
  #      'region_LasVegas', 'region_LosAngeles', 'region_Louisville',
  #      'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',
  #      'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',
  #      'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',
  #      'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',
  #      'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',
  #      'region_Roanoke', 'region_Sacramento', 'region_SanDiego',
  #      'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',
  #      'region_SouthCentral', 'region_Southeast', 'region_Spokane',
  #      'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',
  #      'region_West', 'region_WestTexNewMexico'])
data.extend(l)
print(data)
df=pd.DataFrame(data=[data],columns=['Total Volume', '4046', '4225', '4770', 'Total Bags', 'type', 'year',
       'month', 'Spring', 'Summer', 'Fall', 'Winter', 'region_Albany',
       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',
       'region_Boston', 'region_BuffaloRochester', 'region_California',
       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',
       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',
       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',
       'region_HarrisburgScranton', 'region_HartfordSpringfield',
       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',
       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',
       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',
       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',
       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',
       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',
       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',
       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',
       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',
       'region_SouthCentral', 'region_Southeast', 'region_Spokane',
       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',
       'region_West', 'region_WestTexNewMexico'])
df = Standard_Scaler (df, col_names)
print(df)

print(model.predict(df))

regions=['region_Albany',
       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',
       'region_Boston', 'region_BuffaloRochester', 'region_California',
       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',
       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',
       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',
       'region_HarrisburgScranton', 'region_HartfordSpringfield',
       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',
       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',
       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',
       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',
       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',
       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',
       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',
       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',
       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',
       'region_SouthCentral', 'region_Southeast', 'region_Spokane',
       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',
       'region_West', 'region_WestTexNewMexico']
for i in range(len(regions)):
  print(regions[i][7:])

month=4
if(month==3 or 4 or 5):
  print("hello")

data={"a":[1],"b":[2],"c":[3]}
c=pd.DataFrame(data)

import numpy as np
arr=np.zeros(66)
print(arr)
df=pd.DataFrame(data=[arr],columns=['Total Volume', '4046', '4225', '4770', 'Total Bags', 'type', 'year',
       'month', 'Spring', 'Summer', 'Fall', 'Winter', 'region_Albany',
       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',
       'region_Boston', 'region_BuffaloRochester', 'region_California',
       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',
       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',
       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',
       'region_HarrisburgScranton', 'region_HartfordSpringfield',
       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',
       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',
       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',
       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',
       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',
       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',
       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',
       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',
       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',
       'region_SouthCentral', 'region_Southeast', 'region_Spokane',
       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',
       'region_West', 'region_WestTexNewMexico'])
print(df)



model1.predict(X_test)

import pickle
model = pickle.load(open('model_xgboost.pkl', 'rb'))
prediction=model.predict(df)

prediction

